# 引入Adapter模块

这是一种非常流行且有效的参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）方法。它的核心思想是：冻结BERT主体模型的大部分参数，只为每个任务训练一个轻量级的、可插拔的“适配器”模块（Adapter）。  

这样做的好处：
1. 减少任务冲突：每个任务都有自己专属的一小部分参数（Adapter层），从而避免了在共享权重上的“暴力”竞争，这被称为“软参数共享”，是比硬共享更优的策略。    
2. 训练效率高：由于只训练极少数参数（通常是总参数的1-2%），训练速度更快，对计算资源的要求也更低。    
3. 可扩展性强：未来如果想增加新任务，只需添加一个新的Adapter，而无需从头重新训练整个模型。

在前两次实验中，我们通过任务筛选和损失加权（软调整）来缓解负迁移，但主任务在关键指标（如召回率）上仍无法超越单任务学习。   
这表明，所有任务共享全部BERT层（硬参数共享）的策略本身可能就是瓶颈。

本次实验做了如下的改进：

1. 冻结主干: 我们冻结了预训练BERT模型的绝大部分参数。   
2. 为每个任务添加独立的"适配器": 在BERT的每一层中，我们都为label、expression、target这三个任务插入了各自独立的、轻量级的Adapter模块。
3. 只训练"适配器": 在训练过程中，只有这些新增的Adapter模块和任务独有的分类头会被更新。

这种软参数共享的策略，旨在让每个任务拥有自己专属的“微调路径”，从而在学习共享知识的同时，最大程度地减少任务间的互相干扰。

## 配置
本次实验沿用了上一轮实验中表现较好的配置:
- 激活的任务: `['label', 'expression', 'target']`
- 损失权重: `{'label': 1.0, 'expression': 0.5, 'target': 0.5}`
同时，根据Adapter训练的最佳实践，我们调整了学习率和训练轮数：
- 学习率: 1e-4 (比完全微调稍大)
- Epochs: 5 (Adapter通常收敛更快)

## 运行
直接运行run_adapter_mtl.py即可

~~~
├── MTL_Adapter/
│   ├── data_loader.py      
│   ├── model.py            # 引入Adapter的模型架构
│   ├── trainer.py          
│   ├── run_adapter_mtl.py  # 主脚本，配置Adapter训练
│   └── README.md           # 实验说明
~~~