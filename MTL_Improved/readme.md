# 改进版多任务学习实验 (MTL_Improved)

本项目基于前一版多任务学习（MTL）的实验结果进行了改进。通过分析发现，简单的MTL框架由于任务冲突（特别是困难的sarcasm任务）导致了负迁移，降低了主任务（网络欺凌检测）的性能。  

本次实验旨在通过以下两种策略解决这个问题：

##  1. 任务筛选 (Task Selection)：
- 问题: sarcasm（讽刺检测）任务难度极高，且样本不均衡，可能是主要的干扰源。
- 解决方案: 我们将sarcasm任务从多任务学习框架中移除，只保留主任务label以及两个相关性较强、难度适中的辅助任务expression和target。

##  2. 损失加权 (Loss Weighting)：
- 问题: 默认情况下，所有任务的损失被等同对待，这可能导致模型过多地关注辅助任务，而忽略了我们最关心的主任务。
- 解决方案: 我们为主任务label分配了更高的权重（1.0），为两个辅助任务分配了较低的权重（0.5）。这会引导模型在优化时更加关注主任务的表现。

# 如何运行
直接运行run_improved_mtl.py即可 环境配置就不讲了，默认大家都会了，都到这一步了，不会的AI一下

~~~
---
├── MTL_Improved/
│   ├── data_loader.py      # 只加载选定的任务
│   ├── model.py            # 返回各任务独立的损失
│   ├── trainer.py          # 实现加权损失计算
│   ├── run_improved_mtl.py # 主脚本，配置任务和权重
│   └── README.md           # 本实验说明
~~~
