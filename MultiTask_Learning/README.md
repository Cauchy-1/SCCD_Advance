# 使用多任务学习改进网络欺凌检测

本项目旨在通过**多任务学习 (Multi-Task Learning, MTL)** 的方法，提升中文网络欺凌检测的性能。

# 核心思想
在标准的单任务学习中，模型只专注于一个目标：判断评论是否为网络欺凌。  
在多任务学习框架下，我们让一个共享的 BERT 模型同时学习多个相关的任务：  
- 主任务：判断评论是否为网络欺凌 (label)
- 辅助任务：
    - 判断表达方式是显性还是隐性 (expression)。
    - 判断是否包含讽刺 (sarcasm)。
    - 判断攻击目标是个人还是群体 (target)。
通过学习这些辅助任务，模型被迫去理解更深层次的文本语义和语用特征，这些学习到的丰富特征表示可以反过来帮助模型更好地完成主任务。
  

# 文件结构说明
~~~
├── MultiTask_Learning/
│   ├── data_loader.py      # 多任务数据加载器
│   ├── model.py            # 多任务模型定义
│   ├── trainer.py          # 多任务训练器
│   ├── run_multitask.py    # 主运行脚本
│   └── README.md           # 实验说明
~~~


# 实验运行
直接运行run_experiment.py即可